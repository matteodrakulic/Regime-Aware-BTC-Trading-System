{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Feature Analysis\n",
    "\n",
    "This notebook focuses on analyzing the engineered features extracted from the raw OHLCV data. \n",
    "The goal is to validate the features, understand their statistical properties, and ensure they are suitable for the Regime Detection model (HMM).\n",
    "\n",
    "**Key Objectives:**\n",
    "1. **Data Integrity:** Load and verify the raw data.\n",
    "2. **Feature Construction:** Generate the full set of technical indicators and statistical features.\n",
    "3. **Correlation Analysis:** Identify redundant features to avoid multicollinearity issues.\n",
    "4. **Distribution Analysis:** Examine feature distributions for skewness, kurtosis, and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from src.data.loader import load_ohlcv_csv\n",
    "from src.features.builder import build_features\n",
    "\n",
    "# Plot settings\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "We load the 4-hour Bitcoin OHLCV data. This dataset serves as the foundation for our feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = project_root / \"data/raw/btc_4h.csv\"\n",
    "\n",
    "try:\n",
    "    df = load_ohlcv_csv(data_path)\n",
    "    print(f\"Successfully loaded {len(df)} candles.\")\n",
    "    print(f\"Date Range: {df.index.min()} to {df.index.max()}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file not found at {data_path}\")\n",
    "    print(\"Please ensure the data file exists or run the data fetcher script.\")\n",
    "    # Fallback for demonstration purposes if file is missing (Optional)\n",
    "    # dates = pd.date_range(start='2020-01-01', periods=1000, freq='4h')\n",
    "    # df = pd.DataFrame(index=dates, data={'close': 10000 + np.random.randn(1000).cumsum()})\n",
    "    # df['open'] = df['close'] + np.random.randn(1000)\n",
    "    # df['high'] = df[['open', 'close']].max(axis=1) + 10\n",
    "    # df['low'] = df[['open', 'close']].min(axis=1) - 10\n",
    "    # df['volume'] = np.abs(np.random.randn(1000) * 100)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Construction\n",
    "We use the `build_features` function from our source code to generate the feature set. This includes:\n",
    "- **Returns:** Log returns, rolling means, and standard deviations.\n",
    "- **Volatility:** Realized volatility over different windows.\n",
    "- **Trend:** Moving average convergence divergence (MACD), RSI, etc.\n",
    "- **Distribution:** Skewness and Kurtosis to capture higher moments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = build_features(df)\n",
    "features.dropna(inplace=True)\n",
    "\n",
    "print(f\"Generated {features.shape[1]} features.\")\n",
    "print(f\"Valid data points: {len(features)}\")\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correlation Analysis\n",
    "High correlation between features can lead to multicollinearity, which might confuse the HMM or lead to unstable parameter estimates. We visualize the correlation matrix to identify redundant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 16))\n",
    "corr = features.corr()\n",
    "\n",
    "sns.heatmap(\n",
    "    corr, \n",
    "    annot=False, \n",
    "    cmap='coolwarm', \n",
    "    vmin=-1, \n",
    "    vmax=1, \n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=.5,\n",
    "    cbar_kws={\"shrink\": .5}\n",
    ")\n",
    "plt.title(\"Feature Correlation Matrix\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Distribution Analysis\n",
    "We examine the distributions of key features. Non-Gaussian distributions (fat tails, skew) are common in financial data and are exactly what we hope the HMM regimes will help characterize (e.g., a high-variance regime vs. a low-variance regime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few representative features to analyze\n",
    "key_features = [\n",
    "    'log_return', \n",
    "    'rolling_std_medium', \n",
    "    'trend_rsi_14', \n",
    "    'dist_skew_medium'\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(key_features):\n",
    "    if feature in features.columns:\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        sns.histplot(features[feature], kde=True, bins=50)\n",
    "        plt.title(f\"Distribution of {feature}\")\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plots for Outlier Detection\n",
    "Box plots provide a clear view of the spread and outliers for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "# Normalize data for comparable boxplots\n",
    "features_norm = (features - features.mean()) / features.std()\n",
    "\n",
    "# Plot only a subset to avoid overcrowding\n",
    "subset_cols = features.columns[:10] \n",
    "sns.boxplot(data=features_norm[subset_cols])\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Feature Boxplots (Standardized)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
